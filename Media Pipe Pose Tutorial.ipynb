{"cells":[{"cell_type":"markdown","metadata":{"id":"pqUDmmyma7rg"},"source":["# 0. Install and Import Dependencies"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8638,"status":"ok","timestamp":1670758799479,"user":{"displayName":"­박세현 / 학생 / 데이터사이언스학과","userId":"00484792117661852763"},"user_tz":-540},"id":"MQSdTWVSa7rn","outputId":"bdc854b7-0f73-4f9f-9331-906be69b1313"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mediapipe\n","  Downloading mediapipe-0.9.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.0 MB)\n","\u001b[K     |████████████████████████████████| 33.0 MB 1.3 MB/s \n","\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.6.0.66)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from mediapipe) (3.2.2)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.8/dist-packages (from mediapipe) (4.6.0.66)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mediapipe) (1.21.6)\n","Collecting flatbuffers\u003e=2.0\n","  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n","Requirement already satisfied: protobuf\u003c4,\u003e=3.11 in /usr/local/lib/python3.8/dist-packages (from mediapipe) (3.19.6)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from mediapipe) (1.3.0)\n","Requirement already satisfied: attrs\u003e=19.1.0 in /usr/local/lib/python3.8/dist-packages (from mediapipe) (22.1.0)\n","Requirement already satisfied: python-dateutil\u003e=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib-\u003emediapipe) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,\u003e=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib-\u003emediapipe) (3.0.9)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib-\u003emediapipe) (1.4.4)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib-\u003emediapipe) (0.11.0)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil\u003e=2.1-\u003ematplotlib-\u003emediapipe) (1.15.0)\n","Installing collected packages: flatbuffers, mediapipe\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 1.12\n","    Uninstalling flatbuffers-1.12:\n","      Successfully uninstalled flatbuffers-1.12\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.9.2 requires flatbuffers\u003c2,\u003e=1.12, but you have flatbuffers 22.12.6 which is incompatible.\u001b[0m\n","Successfully installed flatbuffers-22.12.6 mediapipe-0.9.0.1\n"]}],"source":["!pip install mediapipe opencv-python"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":372,"status":"ok","timestamp":1670758857424,"user":{"displayName":"­박세현 / 학생 / 데이터사이언스학과","userId":"00484792117661852763"},"user_tz":-540},"id":"96L6zHjWa7rq"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-1-2f568eff8c2c\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmp_drawing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawing_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmp_pose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}],"source":["import cv2\n","import mediapipe as mp\n","import numpy as np\n","mp_drawing = mp.solutions.drawing_utils\n","mp_pose = mp.solutions.pose\n","from IPython.display import display, Javascript, Image\n","from google.colab.output import eval_js\n","from google.colab.patches import cv2_imshow\n","from base64 import b64decode, b64encode\n","import cv2\n","import numpy as np\n","import PIL\n","import io\n","import html\n","import time\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":359,"status":"ok","timestamp":1670758864906,"user":{"displayName":"­박세현 / 학생 / 데이터사이언스학과","userId":"00484792117661852763"},"user_tz":-540},"id":"vqucVGKR_B9x"},"outputs":[],"source":["# JavaScript to properly create our live video stream using our webcam as input\n","def video_stream():\n","  js = Javascript('''\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","    \n","    var pendingResolve = null;\n","    var shutdown = false;\n","    \n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","    \n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","    \n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","      \n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"\u003cspan\u003eStatus:\u003c/span\u003e\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","           \n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () =\u003e { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () =\u003e { shutdown = true; };\n","      div.appendChild(imgElement);\n","      \n","      const instruction = document.createElement('div');\n","      instruction.innerHTML = \n","          '\u003cspan style=\"color: red; font-weight: bold;\"\u003e' +\n","          'When finished, click here or on the video to stop this demo\u003c/span\u003e';\n","      div.appendChild(instruction);\n","      instruction.onclick = () =\u003e { shutdown = true; };\n","      \n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 480; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","      \n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","      \n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","            \n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","      \n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","      \n","      return {'create': preShow - preCreate, \n","              'show': preCapture - preShow, \n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    ''')\n","\n","  display(js)\n","  \n","def video_frame(label, bbox):\n","  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n","  return data"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1670758864907,"user":{"displayName":"­박세현 / 학생 / 데이터사이언스학과","userId":"00484792117661852763"},"user_tz":-540},"id":"whFBlKQM_IkM","outputId":"0632e7ed-43e7-431a-e85b-9982ba365168"},"outputs":[{"data":{"application/javascript":["\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","    \n","    var pendingResolve = null;\n","    var shutdown = false;\n","    \n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","    \n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","    \n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","      \n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"\u003cspan\u003eStatus:\u003c/span\u003e\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","           \n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () =\u003e { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () =\u003e { shutdown = true; };\n","      div.appendChild(imgElement);\n","      \n","      const instruction = document.createElement('div');\n","      instruction.innerHTML = \n","          '\u003cspan style=\"color: red; font-weight: bold;\"\u003e' +\n","          'When finished, click here or on the video to stop this demo\u003c/span\u003e';\n","      div.appendChild(instruction);\n","      instruction.onclick = () =\u003e { shutdown = true; };\n","      \n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 480; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","      \n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","      \n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","            \n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","      \n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","      \n","      return {'create': preShow - preCreate, \n","              'show': preCapture - preShow, \n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    "],"text/plain":["\u003cIPython.core.display.Javascript object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["video_stream()"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248},"executionInfo":{"elapsed":11,"status":"error","timestamp":1670758579380,"user":{"displayName":"­박세현 / 학생 / 데이터사이언스학과","userId":"00484792117661852763"},"user_tz":-540},"id":"90jY2u_La7rr","outputId":"764237cc-5052-482c-d2d9-f0b28a99a7e2"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-1-c84c48cf2b86\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# VIDEO FEED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mediapipe Feed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"]}],"source":["# VIDEO FEED\n","cap = cv2.VideoCapture(0)\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    cv2.imshow('Mediapipe Feed', frame)\n","    \n","    if cv2.waitKey(10) \u0026 0xFF == ord('q'):\n","        break\n","        \n","cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{"id":"wevdrlAqa7rs"},"source":["# 1. Make Detections"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hag2yOkIa7rt"},"outputs":[],"source":["cap = cv2.VideoCapture(0)\n","## Setup mediapipe instance\n","with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        \n","        # Recolor image to RGB\n","        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        image.flags.writeable = False\n","      \n","        # Make detection\n","        results = pose.process(image)\n","    \n","        # Recolor back to BGR\n","        image.flags.writeable = True\n","        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","        \n","        # Render detections\n","        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n","                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n","                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n","                                 )               \n","        \n","        cv2.imshow('Mediapipe Feed', image)\n","\n","        if cv2.waitKey(10) \u0026 0xFF == ord('q'):\n","            break\n","\n","    cap.release()\n","    cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QFJhcB9va7ru"},"outputs":[],"source":["mp_drawing.DrawingSpec??"]},{"cell_type":"markdown","metadata":{"id":"V2CaIR13a7rv"},"source":["# 2. Determining Joints"]},{"cell_type":"markdown","metadata":{"id":"oyQavhwLa7rv"},"source":["\u003cimg src=\"https://i.imgur.com/3j8BPdc.png\" style=\"height:300px\" \u003e"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xs0Kq7KEa7rw"},"outputs":[],"source":["cap = cv2.VideoCapture(0)\n","## Setup mediapipe instance\n","with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        \n","        # Recolor image to RGB\n","        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        image.flags.writeable = False\n","      \n","        # Make detection\n","        results = pose.process(image)\n","    \n","        # Recolor back to BGR\n","        image.flags.writeable = True\n","        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","        \n","        # Extract landmarks\n","        try:\n","            landmarks = results.pose_landmarks.landmark\n","            print(landmarks)\n","        except:\n","            pass\n","        \n","        \n","        # Render detections\n","        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n","                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n","                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n","                                 )               \n","        \n","        cv2.imshow('Mediapipe Feed', image)\n","\n","        if cv2.waitKey(10) \u0026 0xFF == ord('q'):\n","            break\n","\n","    cap.release()\n","    cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"executionInfo":{"elapsed":474,"status":"error","timestamp":1670749380486,"user":{"displayName":"­박세현 / 학생 / 데이터사이언스학과","userId":"00484792117661852763"},"user_tz":-540},"id":"wsChpezba7rx","outputId":"2f3c6524-fd9b-44a3-9c26-bd77186f3f24"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-7-779a3761151b\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlandmarks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'landmarks' is not defined"]}],"source":["len(landmarks)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1670749380849,"user":{"displayName":"­박세현 / 학생 / 데이터사이언스학과","userId":"00484792117661852763"},"user_tz":-540},"id":"9wH4uzIna7ry","outputId":"35825301-cdfd-4e76-fe58-af326e65cf64"},"outputs":[{"name":"stdout","output_type":"stream","text":["PoseLandmark.NOSE\n","PoseLandmark.LEFT_EYE_INNER\n","PoseLandmark.LEFT_EYE\n","PoseLandmark.LEFT_EYE_OUTER\n","PoseLandmark.RIGHT_EYE_INNER\n","PoseLandmark.RIGHT_EYE\n","PoseLandmark.RIGHT_EYE_OUTER\n","PoseLandmark.LEFT_EAR\n","PoseLandmark.RIGHT_EAR\n","PoseLandmark.MOUTH_LEFT\n","PoseLandmark.MOUTH_RIGHT\n","PoseLandmark.LEFT_SHOULDER\n","PoseLandmark.RIGHT_SHOULDER\n","PoseLandmark.LEFT_ELBOW\n","PoseLandmark.RIGHT_ELBOW\n","PoseLandmark.LEFT_WRIST\n","PoseLandmark.RIGHT_WRIST\n","PoseLandmark.LEFT_PINKY\n","PoseLandmark.RIGHT_PINKY\n","PoseLandmark.LEFT_INDEX\n","PoseLandmark.RIGHT_INDEX\n","PoseLandmark.LEFT_THUMB\n","PoseLandmark.RIGHT_THUMB\n","PoseLandmark.LEFT_HIP\n","PoseLandmark.RIGHT_HIP\n","PoseLandmark.LEFT_KNEE\n","PoseLandmark.RIGHT_KNEE\n","PoseLandmark.LEFT_ANKLE\n","PoseLandmark.RIGHT_ANKLE\n","PoseLandmark.LEFT_HEEL\n","PoseLandmark.RIGHT_HEEL\n","PoseLandmark.LEFT_FOOT_INDEX\n","PoseLandmark.RIGHT_FOOT_INDEX\n"]}],"source":["for lndmrk in mp_pose.PoseLandmark:\n","    print(lndmrk)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"executionInfo":{"elapsed":8,"status":"error","timestamp":1670749381226,"user":{"displayName":"­박세현 / 학생 / 데이터사이언스학과","userId":"00484792117661852763"},"user_tz":-540},"id":"vTnrA8Kla7rz","outputId":"4ede77c3-337c-4fd6-ad9c-01e0170a8370"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-9-c8a530c8c90d\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mlandmarks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmp_pose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPoseLandmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEFT_SHOULDER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'landmarks' is not defined"]}],"source":["landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].visibility"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WJ1bJa7ua7rz"},"outputs":[],"source":["landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KLkKJC6_a7r0"},"outputs":[],"source":["landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value]"]},{"cell_type":"markdown","metadata":{"id":"fjCElTNMa7r0"},"source":["# 3. Calculate Angles"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vAwpTT-Fa7r0"},"outputs":[],"source":["def calculate_angle(a,b,c):\n","    a = np.array(a) # First\n","    b = np.array(b) # Mid\n","    c = np.array(c) # End\n","    \n","    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n","    angle = np.abs(radians*180.0/np.pi)\n","    \n","    if angle \u003e180.0:\n","        angle = 360-angle\n","        \n","    return angle "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EWehpOCBa7r1"},"outputs":[],"source":["shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n","elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n","wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yBElhF5_a7r2"},"outputs":[],"source":["shoulder, elbow, wrist"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZbJT2MOFa7r2"},"outputs":[],"source":["calculate_angle(shoulder, elbow, wrist)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_W8rFqFsa7r3"},"outputs":[],"source":["tuple(np.multiply(elbow, [640, 480]).astype(int))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LeEYnfKfa7r3"},"outputs":[],"source":["cap = cv2.VideoCapture(0)\n","## Setup mediapipe instance\n","with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        \n","        # Recolor image to RGB\n","        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        image.flags.writeable = False\n","      \n","        # Make detection\n","        results = pose.process(image)\n","    \n","        # Recolor back to BGR\n","        image.flags.writeable = True\n","        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","        \n","        # Extract landmarks\n","        try:\n","            landmarks = results.pose_landmarks.landmark\n","            \n","            # Get coordinates\n","            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n","            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n","            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n","            \n","            # Calculate angle\n","            angle = calculate_angle(shoulder, elbow, wrist)\n","            \n","            # Visualize angle\n","            cv2.putText(image, str(angle), \n","                           tuple(np.multiply(elbow, [640, 480]).astype(int)), \n","                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n","                                )\n","                       \n","        except:\n","            pass\n","        \n","        \n","        # Render detections\n","        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n","                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n","                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n","                                 )               \n","        \n","        cv2.imshow('Mediapipe Feed', image)\n","\n","        if cv2.waitKey(10) \u0026 0xFF == ord('q'):\n","            break\n","\n","    cap.release()\n","    cv2.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{"id":"lARCPrtua7r4"},"source":["# 4. Curl Counter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zTsh2A6Ga7r4"},"outputs":[],"source":["cap = cv2.VideoCapture(0)\n","\n","# Curl counter variables\n","counter = 0 \n","stage = None\n","\n","## Setup mediapipe instance\n","with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        \n","        # Recolor image to RGB\n","        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        image.flags.writeable = False\n","      \n","        # Make detection\n","        results = pose.process(image)\n","    \n","        # Recolor back to BGR\n","        image.flags.writeable = True\n","        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","        \n","        # Extract landmarks\n","        try:\n","            landmarks = results.pose_landmarks.landmark\n","            \n","            # Get coordinates\n","            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n","            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n","            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n","            \n","            # Calculate angle\n","            angle = calculate_angle(shoulder, elbow, wrist)\n","            \n","            # Visualize angle\n","            cv2.putText(image, str(angle), \n","                           tuple(np.multiply(elbow, [640, 480]).astype(int)), \n","                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n","                                )\n","            \n","            # Curl counter logic\n","            if angle \u003e 160:\n","                stage = \"down\"\n","            if angle \u003c 30 and stage =='down':\n","                stage=\"up\"\n","                counter +=1\n","                print(counter)\n","                       \n","        except:\n","            pass\n","        \n","        # Render curl counter\n","        # Setup status box\n","        cv2.rectangle(image, (0,0), (225,73), (245,117,16), -1)\n","        \n","        # Rep data\n","        cv2.putText(image, 'REPS', (15,12), \n","                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n","        cv2.putText(image, str(counter), \n","                    (10,60), \n","                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n","        \n","        # Stage data\n","        cv2.putText(image, 'STAGE', (65,12), \n","                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n","        cv2.putText(image, stage, \n","                    (60,60), \n","                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)\n","        \n","        \n","        # Render detections\n","        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n","                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n","                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n","                                 )               \n","        \n","        cv2.imshow('Mediapipe Feed', image)\n","\n","        if cv2.waitKey(10) \u0026 0xFF == ord('q'):\n","            break\n","\n","    cap.release()\n","    cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_8OrbiIFa7r5"},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"mediapipe","language":"python","name":"mediapipe"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":0}